# GPU configuration for Chatterbox TTS API with NVIDIA runtime
# This file extends docker-compose.yml and adds GPU support
#
# Usage:
#   docker compose -f docker-compose.yml -f docker-compose.gpu.yml up
#
# Or use the simplified command:
#   cd docker && docker compose -f docker-compose.gpu.yml up

services:
  chatterbox-tts:
    build:
      dockerfile: docker/Dockerfile
      args:
        BASE_IMAGE: nvidia/cuda:12.4.1-runtime-ubuntu22.04
        PYTORCH_VERSION: 2.6.0
        TORCHVISION_VERSION: 0.21.0
        TORCHAUDIO_VERSION: 2.6.0
        PYTORCH_INDEX: https://download.pytorch.org/whl/cu124
        DEVICE: cuda
        NEEDS_PYTHON_INSTALL: "true"
        EXTRA_PACKAGES: setuptools
    container_name: chatterbox-tts-api-gpu
    environment:
      DEVICE: cuda
      TTS_MODEL_TYPE: ${TTS_MODEL_TYPE:-turbo}
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - ../app:/app/app:ro
      - ../tests:/app/tests:ro
      - ../requirements.txt:/app/requirements.txt:ro
      - ../pyproject.toml:/app/pyproject.toml:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
